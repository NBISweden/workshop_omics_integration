{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# NMF - Negative Matrix Factorization\n",
    "\n",
    "by Sergiu Netotea, PhD, NBIS, Chalmers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recommender systems 1.\n",
    "**How can I explain multi-omics integration to a rich guy?**\n",
    "\n",
    "> \"Research is a derivative of a society's general drift, rarely the opposite.\" :) personal view, reader discretion is advised!\n",
    "\n",
    "- Simple definition: Recommend an item to a user. Existentialists unite! The question \"are we a user or an item?\" has a shadow: \"is a complex disease best described by phenotipic effects or multi-omics causes?\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Rich guys have THE BEST data. Here are some example data tables:\n",
    "    - user/likes section: users/films, users/pictures, users/groceries, users/houses, users/profiles\n",
    "    - item/usage section: item/construction costs, item/delivery options, item/user rankings\n",
    "    - tax avoidance/country section: ... etc\n",
    "- If reccomender systems research had the same budget as multi-omics research:\n",
    "\n",
    "\n",
    "<img src=\"img/budget.jpg\" width=\"200\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Recommender systems 2. Collaborative filtering\n",
    "\n",
    "\n",
    "| User CF             |  Item CF |\n",
    ":--------------------:|:-------------------------:\n",
    "<img src=\"img/user.png\" width=\"200\"/>  | <img src=\"img/item.png\" width=\"200\"/> \n",
    "\n",
    "\n",
    "- Users who share the same interest in certain kind of items will also share the same interest in some other kind of items.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Each user (sample) can be described by k attributes or features. Example: How likely is it that a person suffers from a certain type of cancer?\n",
    "- Each item (gene) can be described by an analagous set of k attributes or features. Example: How likely is it for the gene to be involved/co-regulated/induced etc in a certain type of cancer.\n",
    "- We don't know what these features are, how many are relevant. We learn them, or rather let the machines pick.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Recommender systems 3. - Matrix factorization\n",
    "\n",
    "<img src=\"img/NMF.png\" width=\"300\"/>\n",
    "\n",
    "Hidden representation of a user u predicted rating for item i based on k latent factors (hidden features):\n",
    "- $r_{ui} = x_u y_i^T = \\sum_k{x_{uk} y_{ki}}$\n",
    "- Fit function: $ L = \\sum_{u,i \\in S} (r_{ui} - x_u y_i^T)^2$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Many methods exist, most notable being:\n",
    "    - alternating least squares (ALS): Iteratively fix either $x_u$ or $y_i$. This is because in itself the MF is a non-convex optimization problem that can be turned into a quadratic optimization problem by fixing the factor matrices.\n",
    "    - stochastic gradient descent (SGD): A gradient is computed by the derivative of the loss function for each variable, then the weights are updated by a factor in the opposite direction of the gradient.\n",
    "\n",
    "\n",
    "- For an *ab-initio* example on how to perform general matrix factorization using 2 methods:\n",
    "    - https://blog.insightdatascience.com/explicit-matrix-factorization-als-sgd-and-all-that-jazz-b00e4d9b21ea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### NMF - Non-Negative Matrix Factorization\n",
    "\n",
    "<img src=\"img/segmentation.png\" width=\"200\"/>\n",
    "\n",
    "General model assumption: The higher the factor weight, the more “determined” the column (segment) is by the variable in the row. Ex: Intensity based omics measurements.\n",
    "\n",
    "Exercise: Perform the collaborative filtering in the following article\n",
    "- https://medium.com/logicai/non-negative-matrix-factorization-for-recommendation-systems-985ca8d5c16c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Further read:\n",
    "- NMF outperforms similar techniques at learning parts representation:\n",
    "    - Lee, D., Seung, H. Learning the parts of objects by non-negative matrix factorization. Nature 401, 788–791 (1999). https://doi.org/10.1038/44565\n",
    "\n",
    "\n",
    "  - NMF was probably the best hidden feature based image segmentation prior to CNNs\n",
    "  - In comparison to other MF methods (especially the orthogonality enforcing methods), NMF hidden featurea are not independent, but overlapping, in a hierarchical manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "V = np.array([[0,1,0,1,2,2],\n",
    "              [2,3,1,1,2,2],\n",
    "              [1,1,1,0,1,1],\n",
    "              [0,2,3,4,1,1],\n",
    "              [0,0,0,0,1,0]])\n",
    "\n",
    "V = pd.DataFrame(V, columns=['John', 'Alice', 'Mary', 'Greg', 'Peter', 'Jennifer'])\n",
    "V.index = ['Vegetables', 'Fruits', 'Sweets', 'Bread', 'Coffee']\n",
    "\n",
    "nmf = NMF(3)\n",
    "nmf.fit(V)\n",
    "\n",
    "H = pd.DataFrame(np.round(nmf.components_,2), columns=V.columns)\n",
    "H.index = ['Fruits pickers', 'Bread eaters',  'Veggies']\n",
    "\n",
    "W = pd.DataFrame(np.round(nmf.transform(V),2), columns=H.index)\n",
    "W.index = V.index\n",
    "\n",
    "reconstructed = pd.DataFrame(np.round(np.dot(W,H),2), columns=V.columns)\n",
    "reconstructed.index = V.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## NMF - algorithms\n",
    "\n",
    "- Chen et al, Attention-Based Multi-NMF Deep Neural Network with Multimodality Data for Breast Cancer Prognosis Model, Volume 2019 |Article ID 9523719 | https://doi.org/10.1155/2019/9523719\n",
    "\n",
    "\n",
    "- multiplicative update algorithms\n",
    "- Alternating Least Square\n",
    "- NMF based on Optimal Brain Surgery and Alternate Least Square algorithms\n",
    "- NMF based on projection gradient algorithms\n",
    "- PNMF probabilistic nonnegative matrix factorization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# SNMF - Sparse NMF\n",
    "\n",
    "- Yuan Gao, George Church, Improving molecular cancer class discovery through sparse non-negative matrix factorization, Bioinformatics, Volume 21, Issue 21, , Pages 3970–3975, https://doi.org/10.1093/bioinformatics/bti653\n",
    "- Brunet et al., 2004, Metagenes and molecular pattern discovery using matrix factorization\n",
    "PNAS, Mar 2004, 101 (12) 4164-4169; https://doi.org/10.1073/pnas.0308531101\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- cancer subtyping in microarrays, dealing with sparse data\n",
    "- not integrative (but does that *really* matter?)\n",
    "- rank estimation of NMF models\n",
    "- the representation learned is sparse and hierarchical\n",
    "- $A \\approx WH$ The more sparse the matrix of H, the more sparse is the feature matrix W. Therefore, enforcing the sparseness of H will give rise to metagenes that comprised few dominantly deterministic genes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# jNMF\n",
    "\n",
    "- Fujita, N., Mizuarai, S., Murakami, K. et al. Biomarker discovery by integrated joint non-negative matrix factorization and pathway signature analyses. Sci Rep 8, 9743 (2018). https://doi.org/10.1038/s41598-018-28066-w\n",
    "\n",
    "Main goals:\n",
    "- biomarker discovery\n",
    "- is theoretically and practically equivalent to a standard NMF method with concatenated inputs\n",
    "- common clusters (co-modules) from mRNA expression, microRNA expression, and DNA methylation data of cancer patients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"img/jnmf_pharma.png\" width=\"500\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### JNMF - method details\n",
    "\n",
    "- objective function: $\\sum_{i=1}^N \\|X_i - WH_i\\|$\n",
    "- NMF method was modified to deal with missingness, by using a mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Deep MF\n",
    "\n",
    "- Different NN setups exist for almost every type of MF!\n",
    "- Example: Supervised deep matrix factorization on the MovieLens dataset, using mxnet:\n",
    "    - https://www.oreilly.com/content/deep-matrix-factorization-using-apache-mxnet/\n",
    "- Observation: MF can also be formulated via autoencoders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Advantages:\n",
    "- Take advantage of NN advancements such as mixing batch normalization layers to speed up training time.\n",
    "- Restrict the size of user/item factors independently. Useful in the case where one dimension may be significantly larger than the other and, thus, requires training a massive number of factors\n",
    "\n",
    "<img src=\"img/deep_mf.png\" width=\"300\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "X_train = mx.io.NDArrayIter({'user': train_users, 'movie': train_movies, 'movie_genre': train_genres}, \n",
    "                            label=train_ratings, batch_size=batch_size)\n",
    "X_eval = mx.io.NDArrayIter({'user': valid_users, 'movie': valid_movies, 'movie_genre': valid_genres}, \n",
    "                           label=valid_ratings, batch_size=batch_size)\n",
    "\n",
    "user = mx.symbol.Variable(\"user\")\n",
    "user = mx.symbol.Embedding(data=user, input_dim=n_users, output_dim=15)\n",
    "\n",
    "movie = mx.symbol.Variable(\"movie\")\n",
    "movie = mx.symbol.Embedding(data=movie, input_dim=n_movies, output_dim=20) # Reduce from 25 to 20\n",
    "\n",
    "# We need to add in a third embedding layer for genre\n",
    "movie_genre = mx.symbol.Variable(\"movie_genre\")\n",
    "movie_genre = mx.symbol.Embedding(data=movie_genre, input_dim=20, output_dim=5) # Set to 5\n",
    "\n",
    "y_true = mx.symbol.Variable(\"softmax_label\")\n",
    "\n",
    "nn = mx.symbol.concat(user, movie, movie_genre)\n",
    "nn = mx.symbol.flatten(nn)\n",
    "nn = mx.symbol.FullyConnected(data=nn, num_hidden=64)\n",
    "nn = mx.symbol.Activation(data=nn, act_type='relu')\n",
    "nn = mx.symbol.FullyConnected(data=nn, num_hidden=64)\n",
    "nn = mx.symbol.Activation(data=nn, act_type='relu')\n",
    "nn = mx.symbol.FullyConnected(data=nn, num_hidden=1)\n",
    "\n",
    "y_pred = mx.symbol.LinearRegressionOutput(data=nn, label=y_true)\n",
    "\n",
    "model = mx.module.Module(context=mx.gpu(0), data_names=('user', 'movie', 'movie_genre'), symbol=y_pred)\n",
    "model.fit(X_train, num_epoch=5, optimizer='adam', optimizer_params=(('learning_rate', 0.001),),\n",
    "          eval_metric='rmse', eval_data=X_eval, batch_end_callback=mx.callback.Speedometer(batch_size, 250))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Deep NMF\n",
    "\n",
    "- Flenner, J., & Hunter, B. (2017). A Deep Non-Negative Matrix Factorization Neural Network.\n",
    "    - https://www1.cmc.edu/pages/faculty/BHunter/papers/deep-negative-matrix.pdf\n",
    "\n",
    "\n",
    "- Normal NMF is performed by a single encoding layer \n",
    "\n",
    "<img src=\"img/nmf_onelayer.png\" width=\"200\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "- Deep architecture: CNN, with backpropagation, each NMF layer performs a hierarchical decomposition\n",
    "\n",
    "<img src=\"img/nmf_multilayered.png\" width=\"200\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Matrix Factorization - beyond NMF\n",
    "\n",
    "- Scluster method (a mix of MF and SNF): integrates different types of data and maps them into an effective low-dimensional subspace. First, Scluster uses adaptive sparse reduced-rank regression (S-rrr) to map the original data into the principal subspaces. Next, a fused patient-by-patient network is abstracted for these subgroups by a scaled exponential similarity kernel method. It can then obtain the cancer subtypes by spectral clustering.\n",
    "    - https://pubmed.ncbi.nlm.nih.gov/28113782/\n",
    "- SRF : rank based multi-view bi-clustering, very related to NMF, possibly reducible to it, it does subtyping and identification of subtype-specific features simultaneously.\n",
    "    - https://pubmed.ncbi.nlm.nih.gov/27587661/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Software:\n",
    "- Python:\n",
    "    - recommender systems library: http://surpriselib.com/\n",
    "    - NMF library: http://nimfa.biolab.si/\n",
    "    - https://scikit-learn.org/stable/modules/classes.html#module-sklearn.decomposition\n",
    "- R:\n",
    "    - general NMF: http://cran.r-project.org/package=NMF\n",
    "    - joint NMF library: https://github.com/rikenbit/nnTensor/\n",
    "- Deep Semi NMF: https://github.com/trigeorgis/Deep-Semi-NMF\n",
    "\n",
    "\n",
    "Rank estimation of NMF:\n",
    "- Jean-Philippe Brunet. et. al., (2004). Metagenes and molecular pattern discovery using matrix factorization. PNAS\n",
    "- Xiaoxu Han. (2007). CANCER MOLECULAR PATTERN DISCOVERY BY SUBSPACE CONSENSUS KERNEL CLASSIFICATION\n",
    "- Attila Frigyesi. et. al., (2008). Non-Negative Matrix Factorization for the Analysis of Complex Gene Expression Data: Identification of Clinically Relevant Tumor Subtypes. Cancer Informatics\n",
    "- Haesun Park. et. al., (2019). Lecture 3: Nonnegative Matrix Factorization: Algorithms and Applications. SIAM Gene Golub Summer School, Aussois France, June 18, 2019\n",
    "- Chunxuan Shao. et. al., (2017). Robust classification of single-cell transcriptome data by nonnegative matrix factorization. Bioinformatics\n",
    "\n",
    "\n",
    "Other integrative NMF:\n",
    "\n",
    "\n",
    "- intNMF: https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0176278\n",
    "- Simultaneous Non-negative Matrix Factorization (siNMF) : Extracting Gene Expression Profiles Common to Colon and Pancreatic Adenocarcinoma using Simultaneous nonnegative matrix factorization, Liviu Badea, Pacific Symposium on Biocomputing, 13:279-290, 2009, \n",
    "- Discovery of multi-dimensional modules by integrative analysis of cancer genomic data. Shihua Zhang, et al., Nucleic Acids Research, 40(19), 9379-9391, 2012\n",
    "- Probabilistic Latent Tensor Factorization, International Conference on Latent Variable Analysis and Signal Separation, Y. Kenan Yilmaz et al., 346-353, 2010\n",
    "\n",
    "\n",
    "Fast Tensorial Calculus:\n",
    "\n",
    "\n",
    "- Non-negative Matrix Factorization (NMF) : [Nonnegative Matrix and Tensor Factorizations, Andrzej CICHOCK, et. al., 2009](https://pdfs.semanticscholar.org/94cc/6daad548a03c6edb0351d686c2d4aa364634.pdf), \n",
    "- [A Study on Efficient Algorithms for Nonnegative Matrix/Tensor Factorization, Keigo Kimura, 2017](https://eprints.lib.hokudai.ac.jp/dspace/bitstream/2115/65379/1/Keigo_Kimura.pdf)\n",
    "\n",
    "Non-negative CP Decomposition (NTF)\n",
    "   - α-Divergence (KL, Pearson, Hellinger, Neyman) / β-Divergence (KL, Frobenius, IS) : [Non-negative Tensor Factorization using Alpha and Beta Divergence, Andrzej CICHOCKI et. al., 2007](http://mlg.postech.ac.kr/static/publications/inter_conf/2007/icassp07_cichocki.pdf), [TensorKPD.R (gist of mathieubray)](https://gist.github.com/mathieubray/d83ce9c13fcb60f723f957c13ad85ac5)\n",
    "   - Fast HALS : [Multi-way Nonnegative Tensor Factorization Using Fast Hierarchical Alternating Least Squares Algorithm (HALS), Anh Huy PHAN et. al., 2008](http://www.ieice.org/proceedings/NOLTA2008/articles/A1L-D3-Phan-2045.pdf)\n",
    "   - α-HALS/β-HALS : [Fast Local Algorithms for Large Scale Nonnegative Matrix and Tensor Factorizations, Andrzej CICHOCKI et. al., 2008](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.214.6398&rep=rep1&type=pdf)\n",
    "- Non-negative Tucker Decomposition (NTD)\n",
    "   - KL, Frobenius : [Nonnegative Tucker Decomposition, Yong-Deok Kim et. al., 2007](https://pdfs.semanticscholar.org/f388/99be8ebd8b9aa7029b2b4f187dac4b04d816.pdf)\n",
    "   - α-Divergence (KL, Pearson, Hellinger, Neyman) / β-Divergence (KL, Frobenius, IS) : [Nonneegative Tucker Decomposition With Alpha-Divergence, Yong-Deok Kim et. al., 2008](https://pdfs.semanticscholar.org/f01b/7354619f053863048217c58cc517def86aeb.pdf), [Fast and efficient algorithms for nonnegative Tucker decomposition, Anh Huy Phan, 2008](https://link.springer.com/chapter/10.1007/978-3-540-87734-9_88)\n",
    "   - Fast HALS : [Extended HALS algorithm for nonnegative Tucker decomposition and its applications for multiway analysis and classification, Anh Hyu Phan et. al., 2011](https://www.sciencedirect.com/science/article/pii/S0925231211000427)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

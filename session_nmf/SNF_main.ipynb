{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Network fusion\n",
    "\n",
    "Sergiu Netotea, PhD, NBIS, Chalmers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Network models are a very complex representation of data\n",
    "\n",
    "\n",
    "- power law sophistication: for every n vertices there are up to n(n-1) possible edges\n",
    "- data in biology is typically suffering from the curse of dimensionality\n",
    "- differences in scale, collection bias and noise in each data set\n",
    "- complementary nature of the information provided by different types of data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- the potential for feature cleaning and data transformation using a network structure are great\n",
    "- one important tradeoff: losing a weak signal due to a poorly made network model\n",
    "- one important benefit: recovering a weak signal due to the cummulative power of weak links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Typical dataset:\n",
    "- features: samples, patients, genes, metabolites, clinical descriptors etc\n",
    "- instances: any repeated measurements of the above!\n",
    "\n",
    "> Via network modelling, all instances are turned into feature relationships (data structure becomes uni-dimensional)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Common network (graph) representation:\n",
    "- Nodes (vertices): features\n",
    "- Links (edges): numerical relationship between nodes (directional, boolean, discrete, continuous)\n",
    "\n",
    "> Via **network fusion**, the feature relationships (links) are described based on multiple datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![NF basics](img/nf_basics.png \"NF basics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## How can networks be fused?\n",
    "\n",
    "*Simple rule: average edge values by summing up adjacency matrices!*\n",
    "    \n",
    "Pitfalls:\n",
    "- Most omics networks are sparse: some feature relationships eh .. are prevalent only on certain 'omics levels!\n",
    "- Guilt of association is not captured: features similar to pan-omics features should not the treated equally.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "*Complex rule: take in consideration the infomation difussivity in each network when fusing them!*\n",
    "\n",
    "- in graph computing this is called \"message passing\".\n",
    "- pitfalls: model parametrization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# (Perceived) advantages of network fusion\n",
    "\n",
    "Very useful when: \n",
    "- data is incomplete\n",
    "- dataset quality is not uniform\n",
    "- data from multiple sources is used\n",
    "- networks can be built in complex ways, taking into account additional, annotated information.\n",
    "- easy to transfer knowledge from alternative models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "It is a generative model!\n",
    "- example: generate data from similarity matrix\n",
    "    - https://en.wikipedia.org/wiki/Multidimensional_scaling\n",
    "- the generated networks can be used for graph clustering, regression, classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# SNF: Similarity Network Fusion\n",
    "\n",
    "Wang, Bo et al. “Similarity network fusion for aggregating data types on a genomic scale.” Nature methods vol. 11,3 (2014): 333-7.\n",
    "\n",
    "https://doi.org/10.1038/nmeth.2810\n",
    "\n",
    "\n",
    "- mRNA expression, DNA methylation and microRNA (miRNA) expression data for five cancer data sets.\n",
    "- clustering cancer subtypes and predicting survival\n",
    "- uses networks of samples (patient networks) as a basis for integration. \n",
    "- at the time patient-similarity networks have not been used specifically for integrating biological data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Similarity networks\n",
    "\n",
    "- At every 'omics level, there are multiple ways to compute a network.\n",
    "- Similarity networks are only investigating the similarity of one feature to another, with regards to a distance measure.\n",
    "- Every similarity distance is different. See https://en.wikipedia.org/wiki/Metric_space\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![similarity](img/similarity.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Method - Similarity distance:\n",
    "\n",
    "- contininuous data: euclidean distance, weighted using an exponential kernel function\n",
    "    - TODO: describe the regularization step\n",
    "- discrete data: chi squared distance\n",
    "$\\sum_{i=1}^{n} \\cfrac{(x_i - y_i)^2} {(x_i + y_i)}$\n",
    "- boolean data: agreement based distances (Jaccard, Hamming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Method - Inductive network fusion (1)\n",
    "\n",
    "- In order to fuse the supplied m simmilarity (affinity) matrices, each must be normalized. A traditional normalization on an affinity matrix would suffer from numerical instabilities due to the self-similarity along the diagonal; thus, a modified normalization is used:\n",
    "\n",
    "$$\n",
    "      \\mathbf{P}(i,j) =\n",
    "         \\left\\{\\begin{array}{rr}\n",
    "           \\frac{\\mathbf{W}_(i,j)}\n",
    "                 {2 \\sum_{k\\neq i}^{} \\mathbf{W}_(i,k)} ,& j \\neq i \\\\\n",
    "                                                       1/2 ,& j = i\n",
    "         \\end{array}\\right.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Under the assumption that local similarities are more important than distant ones, a more sparse weight matrix is calculated based on a KNN framework:\n",
    "\n",
    "$$\n",
    "      \\mathbf{S}(i,j) =\n",
    "         \\left\\{\\begin{array}{rr}\n",
    "           \\frac{\\mathbf{W}_(i,j)}\n",
    "                 {\\sum_{k\\in N_{i}}^{}\\mathbf{W}_(i,k)} ,& j \\in N_{i} \\\\\n",
    "                                                         0 ,& \\text{otherwise}\n",
    "         \\end{array}\\right.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Method - Inductive network fusion (2)\n",
    "\n",
    "- The two weight matrices P and S thus provide information about a given patient's similarity to all other patients and the K most similar patients, respectively.\n",
    "- These m matrices are then iteratively fused. At each iteration, the matrices are made more similar to each other via:\n",
    "\n",
    "$$\n",
    "\\mathbf{P}^{(v)} = \\mathbf{S}^{(v)}\n",
    "                          \\times\n",
    "                          \\frac{\\sum_{k\\neq v}^{}\\mathbf{P}^{(k)}}{m-1}\n",
    "                          \\times\n",
    "                          (\\mathbf{S}^{(v)})^{T},\n",
    "                          v = 1, 2, ..., m\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Obs:\n",
    "- After each iteration, the resultant P matrices are normalized via the equation above.\n",
    "- Fusion stops after `t` iterations, or when the matrices $\\mathbf{P}^{(v)}, v = 1, 2, ..., m$ converge.\n",
    "- The output fused matrix is full rank and can be subjected to clustering and classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Different usage of the fused matrix:\n",
    "- clustering: spectral clustering, consensus clustering\n",
    "- network model based subtype prediction: label propagation\n",
    "- network model based feature selection: measuring the change in consistence brought by SNF on a single feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Post-fusion analysis - Spectral clustering\n",
    "\n",
    "- eigenvalues, eigenvectors $A x = \\lambda x$\n",
    "- graph laplacian: degree matrix - adjacency matrix\n",
    "- the increasing ordered eigenvalues of the graph laplacian matrix are describing the clusters in their increased network effect\n",
    "\n",
    "Also see: K-neighbors clustering, MCL clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Consensus clustering\n",
    "\n",
    "- Monti, S., Tamayo, P., Mesirov, J. et al. Consensus Clustering: A Resampling-Based Method for Class Discovery and Visualization of Gene Expression Microarray Data. Machine Learning 52, 91–118 (2003). https://doi.org/10.1023/A:1023949509487\n",
    "- Implementation: http://www.bioconductor.org/packages/release/bioc/html/CancerSubtypes.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "SNF drawbacks:\n",
    "- the unstable nature of kernel-based clustering \n",
    "- sensitive to small changes in molecular measurements\n",
    "- need for hyper-parametrization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Details:\n",
    "- The data are first partitioned with different values of k (number of clusters).\n",
    "- For each value of k, we construct the pair-wise connectivity matrix.\n",
    "- To identify the number of clusters we add noise to the data and then build the pair-wise connectivity for the perturbed data.\n",
    "- We calculate the discrepancy in pair-wise connectivity between before and after data perturbation. We choose opt_k as the optimal number of clusters for which the pair-wise connectivity is the most stable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Integrative SNF-CC example:\n",
    "\n",
    "- Nguyen, Tin et al. “A novel approach for data integration and disease subtyping.” Genome research vol. 27,12 (2017): 2025-2039.\n",
    "- https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5741060/\n",
    "\n",
    "Stages:\n",
    "- construct the combined similarity matrix between patients using the connectivity information from individual data types. \n",
    "- partition the patients using the integrated similarity matrix.\n",
    "- further split each discovered group of patients into subgroups if possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Weighted similarity network fusion\n",
    "\n",
    "Links:\n",
    "- Xu T, Le TD, Liu L, Wang R, Sun B, et al. (2016) Identifying Cancer Subtypes from miRNA-TF-mRNA Regulatory Networks and Expression Data. PLOS ONE 11(4): e0152792. https://doi.org/10.1371/journal.pone.0152792\n",
    "- Implementation:\n",
    "    - https://rdrr.io/bioc/CancerSubtypes/\n",
    "    - https://rdrr.io/cran/IntClust/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## WSNF - Method (1)\n",
    "\n",
    "1. Compute PageRank based ranking of features. Important features are ranked based on the in-number of TFs.\n",
    "    - Build the regulatory network where the nodes represent the features, i.e. the microRNAs (miRNAs), transcription factors (TFs) and messenger RNAs (mRNAs) and the edges indicate the interactions between the features.\n",
    "    - The interactions are retrieved from various interatomic databases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"img/wsnf_data.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## WSNF - Method (2)\n",
    "\n",
    "2. Integrate feature ranking with feature variation. Gene expression based.\n",
    "    - Use knn based kernels and the expression data of the miRNAs, TFs and mRNAs to calculate the weight of the features, representing the level of importance of the features.\n",
    "3. Weighted SNF\n",
    "    - The feature weight is then integrated into a network fusion approach to cluster the samples (patients) and thus to identify cancer subtypes. \n",
    "    - $D(s_i, s_j) = \\sqrt{\\sum_{m=1}^p{W(f_m)*(f_m^{s_i}-f_m^{s_j})^2}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"img/wsnf.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ANF - Affinity network fusion\n",
    "\n",
    "- Tianle Ma, Aidong Zhang, Affinity Network Fusion and Semi-supervised Learning for Cancer Patient Clustering, 2019, https://doi.org/10.1016/j.ymeth.2018.05.020\n",
    "- Software: https://www.bioconductor.org/packages/release/bioc/html/ANF.html\n",
    "    - https://github.com/BeautyOfWeb/ANF\n",
    "- Data: gene expression, miRNA expression and DNA methylation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"img/anf_alg.jpg\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Overall, the methodology is similar to SNF. Weak edges derived from a similarity distance are pruned using a kNN based kernel. The same is acomplished using the message passing kernel in SNF.\n",
    "- The matrix fusion process is random-walk based, and it is a bit more clear, although it parametrizes feature importance with a set of omics-specific weights:\n",
    "    - $ W = \\sum_{v=1}^n{w_v * W^{(v)}}$, $\\sum_{v=1}^n{w_v}=1$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- W regarded as a \"state transition matrix\", and multiplying it r times is a random walk in its generated graph. $W = W^r$\n",
    "    - this step is similar to the inductive message passing in SNF\n",
    "    - r parameter must be small (2, 3), or W becomes a rank one matrix\n",
    "    - a more complex random walk was also explored, that uses some of the knn pruned weaker edges.\n",
    "\n",
    "> **Obs.** While the SNF fitting process might look long, the patient matrix is usually a small network (most clinical datasets are in the order of tens - hundreds)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ANF - Semi-supervised learning on patient affinity networks\n",
    "\n",
    "https://arxiv.org/abs/1805.09673\n",
    "\n",
    "- a good example for the potential of NF to combine supervised and unsupervised learning through good representation learning.\n",
    "- 97% accuracy on test set with training less than 1% of data for classifying patients into correct disease types\n",
    "- ANF obtains effective kNN-based nonlinear transformations that reduce noise in multi-omic data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"img/anf_nn.jpg\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Subsequent studies:\n",
    "\n",
    "- Guo, Yang et al. “Improvement of cancer subtype prediction by incorporating transcriptome expression data and heterogeneous biological networks.” BMC medical genomics vol. 11,Suppl 6 119. 31 Dec. 2018, doi:10.1186/s12920-018-0435-x\n",
    "- https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6311915/\n",
    "\n",
    "Main ideas:\n",
    "- ANF did not consider the feature importance and the feature relationships in data integration (different regulatory mechanisms may exist in different cancer subtypes).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Method: CSPRV (Cancer Subtype Prediction using RV2)\n",
    "> Given the expression data of genome elements, we first extract multiple expression features for each regulatory element based on the heterogeneous biological networks. Based on the extracted feature matrices of samples, we use a matrix correlation method, RV2, to predict the similarities between samples in each expression data-view, and then fuse the similarity information in samples from all considering data-views according to different integration weights. Finally, we cluster patient samples into different cancer subtypes based on the predicted integrative similarity network between samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## SKF - Similarity Kernel Fusion\n",
    "\n",
    "- https://en.wikipedia.org/wiki/Kernel_method\n",
    "- multiple papers:\n",
    "    - Jiang, Limin et al. “Discovering Cancer Subtypes via an Accurate Fusion Strategy on Multiple Profile Data.” Frontiers in genetics vol. 10 20. 5 Feb. 2019, doi:10.3389/fgene.2019.00020\n",
    "    - https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6370730/\n",
    "    - https://pubmed.ncbi.nlm.nih.gov/30619454/\n",
    "    - https://pubmed.ncbi.nlm.nih.gov/31514111/\n",
    "- Also search for MKL (multiple kernel learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The Kernel trick\n",
    "\n",
    "- (wikipedia) \"kernel functions, enable them to operate in a high-dimensional, implicit feature space without ever computing the coordinates of the data in that space, but rather by simply computing the inner products between the images of all pairs of data in the feature space.\"\n",
    "\n",
    "\n",
    "$P_l^{t+1}=\\alpha(S_l \\times \\frac{\\sum_{r \\neq l}P_r^t}{n} \\times S_l^T) + (1-\\alpha) \\frac{\\sum_{r \\neq l}P_r^t}{n}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"img/skf.png\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Papers:\n",
    "- SNF similarity network fusion: https://www.nature.com/articles/nmeth.2810\n",
    "    - https://media.nature.com/original/nature-assets/nmeth/journal/v11/n3/extref/nmeth.2810-S1.pdf\n",
    "- SNF.CC: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5741060/\n",
    "- WSNF: https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0152792\n",
    "- SKF: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6370730/#:~:text=(2016)%20proposed%20Weighted%20Similarity%20Network,cancer%20types%20to%20demonstrate%20performance.\n",
    "- Speicher and Pfeifer (2015) https://pubmed.ncbi.nlm.nih.gov/26072491/ pointed out that iCluster has high computational complexity and proposed a dimensionality reduction method to integrate multiple similarity kernels. This method is evaluated by using five cancer types. \n",
    "- ANF affinity network fusion: https://arxiv.org/abs/1805.09673 \n",
    "- INF integrative network fusion: https://www.frontiersin.org/articles/10.3389/fonc.2020.01065/full\n",
    "- fusion methods review (2020): https://www.sciencedirect.com/science/article/pii/S2001037019304155\n",
    "- icluster: https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0035236\n",
    "    - https://pubmed.ncbi.nlm.nih.gov/19759197/\n",
    "- IntClust https://rdrr.io/cran/IntClust/\n",
    "\n",
    "\n",
    "\n",
    "# Software:\n",
    "- ANF: https://www.bioconductor.org/packages/release/bioc/html/ANF.html\n",
    "    - https://github.com/BeautyOfWeb/ANF\n",
    "- R: CancerSubtypes https://bioconductor.org/packages/devel/bioc/vignettes/CancerSubtypes/inst/doc/CancerSubtypes-vignette.html\n",
    "- SNF Python: https://github.com/rmarkello/snfpy\n",
    "- SNF IntClust: https://rdrr.io/cran/IntClust/man/SNF.html\n",
    "\n",
    "# Personal stuff (ignore!):\n",
    "- https://github.com/NBISweden/workshop_omics_integration/\n",
    "- https://www.sciencedirect.com/science/article/abs/pii/S1746809419301326\n",
    "- iomicspass: https://www.nature.com/articles/s41540-019-0099-y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
